nfactors=3,
file = "SEE_adju_EFA.doc"
)
write.csv(factor.scores(SEE_adju%>%
select(-ID),f=SEE_adju_fa)$score,"SEE_adju_score.csv")
SEE_adju_score<-read.csv("SEE_adju_score.csv")%>%
cbind(SEE_adju%>%select(ID))
write.csv(SEE_adju_score,"SEE_adju_score.csv")
SEE_adju_score<-read.csv("SEE_adju_score.csv")
head(SEE_adju_score)
SEE_adju_score<-SEE_adju_score%>%
select(-c("X.1","X"))%>%
rename("焦虑抑郁"=PA2,
"拖延"=PA1,
"主观幸福感"=PA3)
View(task_q_score)
head(SEE_adju_score)
regress3<-task_q_score%>%
select(-X)%>%
merge(SEE_adju_score,by="ID")
head(regress3)
regress3$焦虑抑郁
regress3$焦虑抑郁
# 定义自变量（X）和因变量（y）
X <- regress3%>%
select(-c("拖延","焦虑抑郁","主观幸福感","ID"))
y <- regress3$焦虑抑郁
# 划分训练集和测试集
set.seed(123) # 为了可重复性设置随机种子
trainIndex <- sample(1:nrow(X), 0.8*nrow(X)) # 随机选择80%的数据作为训练集
X_train <- X[trainIndex, ]
y_train <- y[trainIndex]
X_test <- X[-trainIndex, ]
y_test <- y[-trainIndex]
# 训练随机森林模型
rf_model <- randomForest(x = X_train, y = y_train, ntree = 500, importance = TRUE)
# 在测试集上进行预测
y_pred <- predict(rf_model, newdata = X_test)
# 评估模型性能
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
cat("RMSE:", rmse, "\n")
# R^2
r2 <- cor(y_pred, y_test)^2
cat("R^2:", r2, "\n")
# 显示变量的重要性
importance <- importance(rf_model)
cat("Feature Importances:\n")
print(importance)
# 定义自变量（X）和因变量（y）
X <- regress3%>%
select(-c("拖延","焦虑抑郁","主观幸福感","ID"))
y <- regress3$拖延
# 划分训练集和测试集
set.seed(123) # 为了可重复性设置随机种子
trainIndex <- sample(1:nrow(X), 0.8*nrow(X)) # 随机选择80%的数据作为训练集
X_train <- X[trainIndex, ]
y_train <- y[trainIndex]
X_test <- X[-trainIndex, ]
y_test <- y[-trainIndex]
# 训练随机森林模型
rf_model <- randomForest(x = X_train, y = y_train, ntree = 500, importance = TRUE)
# 在测试集上进行预测
y_pred <- predict(rf_model, newdata = X_test)
# 评估模型性能
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
cat("RMSE:", rmse, "\n")
# R^2
r2 <- cor(y_pred, y_test)^2
cat("R^2:", r2, "\n")
# 显示变量的重要性
importance <- importance(rf_model)
cat("Feature Importances:\n")
print(importance)
# 定义自变量（X）和因变量（y）
X <- regress3%>%
select(-c("拖延","焦虑抑郁","主观幸福感","ID"))
y <- regress3$拖延
# 划分训练集和测试集
set.seed(123) # 为了可重复性设置随机种子
trainIndex <- sample(1:nrow(X), 0.8*nrow(X)) # 随机选择80%的数据作为训练集
X_train <- X[trainIndex, ]
y_train <- y[trainIndex]
X_test <- X[-trainIndex, ]
y_test <- y[-trainIndex]
# 训练随机森林模型
rf_model <- randomForest(x = X_train, y = y_train, ntree = 500, importance = TRUE)
# 在测试集上进行预测
y_pred <- predict(rf_model, newdata = X_test)
# 评估模型性能
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
cat("RMSE:", rmse, "\n")
# R^2
r2 <- cor(y_pred, y_test)^2
cat("R^2:", r2, "\n")
# 显示变量的重要性
importance <- importance(rf_model)
cat("Feature Importances:\n")
print(importance)
regress3$拖延
regress3$主观幸福感
# 定义自变量（X）和因变量（y）
X <- regress3%>%
select(-c("拖延","焦虑抑郁","主观幸福感","ID"))
y <- regress3$主观幸福感
# 划分训练集和测试集
set.seed(123) # 为了可重复性设置随机种子
trainIndex <- sample(1:nrow(X), 0.8*nrow(X)) # 随机选择80%的数据作为训练集
X_train <- X[trainIndex, ]
y_train <- y[trainIndex]
X_test <- X[-trainIndex, ]
y_test <- y[-trainIndex]
# 训练随机森林模型
rf_model <- randomForest(x = X_train, y = y_train, ntree = 500, importance = TRUE)
# 在测试集上进行预测
y_pred <- predict(rf_model, newdata = X_test)
# 评估模型性能
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
cat("RMSE:", rmse, "\n")
# R^2
r2 <- cor(y_pred, y_test)^2
cat("R^2:", r2, "\n")
# 显示变量的重要性
importance <- importance(rf_model)
cat("Feature Importances:\n")
print(importance)
View(SEE_q_socre)
View(SEE_q_socre)
regress1<-SEE_q_socre%>%
select(-c("X"))%>%
merge(SEE_adju_score,by="ID")
head(regress1)
# 定义自变量（X）和因变量（y）
X <- regress1%>%
select(-c("拖延","焦虑抑郁","主观幸福感","ID"))
y <- regress1$焦虑抑郁
# 划分训练集和测试集
set.seed(123) # 为了可重复性设置随机种子
trainIndex <- sample(1:nrow(X), 0.8*nrow(X)) # 随机选择80%的数据作为训练集
X_train <- X[trainIndex, ]
y_train <- y[trainIndex]
X_test <- X[-trainIndex, ]
y_test <- y[-trainIndex]
# 训练随机森林模型
rf_model <- randomForest(x = X_train, y = y_train, ntree = 500, importance = TRUE)
# 在测试集上进行预测
y_pred <- predict(rf_model, newdata = X_test)
# 评估模型性能
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
cat("RMSE:", rmse, "\n")
# R^2
r2 <- cor(y_pred, y_test)^2
cat("R^2:", r2, "\n")
# 显示变量的重要性
importance <- importance(rf_model)
cat("Feature Importances:\n")
print(importance)
# 定义自变量（X）和因变量（y）
X <- regress1%>%
select(-c("拖延","焦虑抑郁","主观幸福感","ID"))
y <- regress1$拖延
# 划分训练集和测试集
set.seed(123) # 为了可重复性设置随机种子
trainIndex <- sample(1:nrow(X), 0.8*nrow(X)) # 随机选择80%的数据作为训练集
X_train <- X[trainIndex, ]
y_train <- y[trainIndex]
X_test <- X[-trainIndex, ]
y_test <- y[-trainIndex]
# 训练随机森林模型
rf_model <- randomForest(x = X_train, y = y_train, ntree = 500, importance = TRUE)
# 在测试集上进行预测
y_pred <- predict(rf_model, newdata = X_test)
# 评估模型性能
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
cat("RMSE:", rmse, "\n")
# R^2
r2 <- cor(y_pred, y_test)^2
cat("R^2:", r2, "\n")
# 显示变量的重要性
importance <- importance(rf_model)
cat("Feature Importances:\n")
print(importance)
# 定义自变量（X）和因变量（y）
X <- regress1%>%
select(-c("拖延","焦虑抑郁","主观幸福感","ID"))
y <- regress1$主观幸福感
# 划分训练集和测试集
set.seed(123) # 为了可重复性设置随机种子
trainIndex <- sample(1:nrow(X), 0.8*nrow(X)) # 随机选择80%的数据作为训练集
X_train <- X[trainIndex, ]
y_train <- y[trainIndex]
X_test <- X[-trainIndex, ]
y_test <- y[-trainIndex]
# 训练随机森林模型
rf_model <- randomForest(x = X_train, y = y_train, ntree = 500, importance = TRUE)
# 在测试集上进行预测
y_pred <- predict(rf_model, newdata = X_test)
# 评估模型性能
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
cat("RMSE:", rmse, "\n")
# R^2
r2 <- cor(y_pred, y_test)^2
cat("R^2:", r2, "\n")
# 显示变量的重要性
importance <- importance(rf_model)
cat("Feature Importances:\n")
print(importance)
View(task_SE)
regress2<-task_SE_score%>%
select(-c("X"))%>%
merge(SEE_adju_score,by="ID")
head(regress2)
# 定义自变量（X）和因变量（y）
X <- regress2%>%
select(-c("拖延","焦虑抑郁","主观幸福感","ID"))
y <- regress2$焦虑抑郁
# 划分训练集和测试集
set.seed(123) # 为了可重复性设置随机种子
trainIndex <- sample(1:nrow(X), 0.8*nrow(X)) # 随机选择80%的数据作为训练集
X_train <- X[trainIndex, ]
y_train <- y[trainIndex]
X_test <- X[-trainIndex, ]
y_test <- y[-trainIndex]
# 训练随机森林模型
rf_model <- randomForest(x = X_train, y = y_train, ntree = 500, importance = TRUE)
# 在测试集上进行预测
y_pred <- predict(rf_model, newdata = X_test)
# 评估模型性能
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
cat("RMSE:", rmse, "\n")
# R^2
r2 <- cor(y_pred, y_test)^2
cat("R^2:", r2, "\n")
# 显示变量的重要性
importance <- importance(rf_model)
cat("Feature Importances:\n")
print(importance)
# 定义自变量（X）和因变量（y）
X <- regress2%>%
select(-c("拖延","焦虑抑郁","主观幸福感","ID"))
y <- regress2$拖延
# 划分训练集和测试集
set.seed(123) # 为了可重复性设置随机种子
trainIndex <- sample(1:nrow(X), 0.8*nrow(X)) # 随机选择80%的数据作为训练集
X_train <- X[trainIndex, ]
y_train <- y[trainIndex]
X_test <- X[-trainIndex, ]
y_test <- y[-trainIndex]
# 训练随机森林模型
rf_model <- randomForest(x = X_train, y = y_train, ntree = 500, importance = TRUE)
# 在测试集上进行预测
y_pred <- predict(rf_model, newdata = X_test)
# 评估模型性能
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
cat("RMSE:", rmse, "\n")
# R^2
r2 <- cor(y_pred, y_test)^2
cat("R^2:", r2, "\n")
# 显示变量的重要性
importance <- importance(rf_model)
cat("Feature Importances:\n")
print(importance)
# 定义自变量（X）和因变量（y）
X <- regress2%>%
select(-c("拖延","焦虑抑郁","主观幸福感","ID"))
y <- regress2$主观幸福感
# 划分训练集和测试集
set.seed(123) # 为了可重复性设置随机种子
trainIndex <- sample(1:nrow(X), 0.8*nrow(X)) # 随机选择80%的数据作为训练集
X_train <- X[trainIndex, ]
y_train <- y[trainIndex]
X_test <- X[-trainIndex, ]
y_test <- y[-trainIndex]
# 训练随机森林模型
rf_model <- randomForest(x = X_train, y = y_train, ntree = 500, importance = TRUE)
# 在测试集上进行预测
y_pred <- predict(rf_model, newdata = X_test)
# 评估模型性能
mse <- mean((y_pred - y_test)^2)
rmse <- sqrt(mse)
cat("RMSE:", rmse, "\n")
# R^2
r2 <- cor(y_pred, y_test)^2
cat("R^2:", r2, "\n")
# 显示变量的重要性
importance <- importance(rf_model)
cat("Feature Importances:\n")
print(importance)
View(day0t2_q_des)
ALT1_all <- ALT1_all%>%mutate(ID = as.character(ID)) %>%
mutate(ParticipantID = as.character(ParticipantID)) %>%
mutate(rt=as.numeric(rt))%>% #转变被试编号和反应时类型为字符型与数值型
mutate(correct = ifelse(correct == "true", 1, ifelse(correct == "false", 0, NA)))%>% ##重编码correct，1对0错
filter(screen_id%in%c("formal_ALT1_1","formal_ALT1_2"))%>%
filter(rt>=200 & rt <=1200)#筛出反应时在200~1200
ALT1_analysis<-function(data){
#**总体匹配/不匹配雨云图*
ALT1 <-data%>% #选择正式实验的数据
group_by(ID,conditionType) %>%  #按被试与条件分组
summarise(
avg_rt = mean(rt, na.rm = TRUE),#每个被试在类似"circle_match"条件下所有trial的平均反应时
max_rt = max(rt, na.rm = TRUE),#每个被试在类似"circle_match"条件下所有trial的最大反应时
min_rt = min(rt, na.rm = TRUE),#每个被试在类似"circle_match"条件下所有trial的最小反应时
sd_rt=sd(rt, na.rm = TRUE), #每个被试在类似"circle_match"条件下所有trial的反应时的方差
all_count=n(),#每个被试在每个条件的总trial数量
row_count = sum(rt>=200 & rt <=1200, na.rm = TRUE),  #每个条件反应时符合条件的总数,舍弃按键太快和按键太慢的
correct_count = sum(correct == 1 & rt>=200 & rt <=1200, na.rm = TRUE),
acc = correct_count /all_count )%>%#计算每个被试在每个条件的正确率= 正确/总数
mutate(conditionType = case_when(
conditionType == "match" ~ "匹配",
conditionType == "nonmatch"~ "不匹配",
))
print(ALT1)
colors <- c("lightblue", "grey", "green", "purple", "orange")
# ACC plot
acc_plot <- ggplot(ALT1, aes(x = conditionType, y = acc, fill =conditionType , colour = conditionType)) +
geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2, trim = FALSE, alpha = 0.5) +
geom_point(position = position_jitter(width = .15), size = .25, alpha = 0.5) +
geom_boxplot(aes(x = conditionType, y = acc), outlier.shape = NA, alpha = 0.5, width = .1, colour = "BLACK") +
ylab('正确率') + xlab('条件') + coord_flip() +
theme_cowplot() + guides(fill = FALSE, colour = FALSE) +
scale_colour_manual(values = colors) +#palette = "Dark2"
scale_fill_manual(values = colors) +#palette = "Dark2"
ggtitle("Figure a: ACC of ALT1")
# RT plot
rt_plot <- ggplot(ALT1, aes(x = conditionType, y = avg_rt, fill = conditionType, colour = conditionType)) +
geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2, trim = FALSE, alpha = 0.5) +
geom_point(position = position_jitter(width = .15), size = .25, alpha = 0.5) +
geom_boxplot(aes(x = conditionType, y = avg_rt), outlier.shape = NA, alpha = 0.5, width = .1, colour = "BLACK") +
ylab('反应时（ms）')  + coord_flip() +#+ xlab('conditionType')
theme_cowplot() + guides(fill = FALSE, colour = FALSE) +
scale_colour_manual(values = colors) +#palette = "Dark2"
scale_fill_manual(values = colors) +#palette = "Dark2"
ggtitle("Figure b: RT of ALT1")
# Combine plots vertically
final_plot <- acc_plot | rt_plot
#ggsave(output_file, final_plot, width = 10, height = 15) #输出保存到文件夹
print(final_plot)
ggsave("fig1_ALT1.png", final_plot, width = 10, height = 8, dpi = 300)
#**各图形x匹配/不匹配的反应时与正确率的雨云图*
ALT1_data <-data%>% #选择正式实验的数据
group_by(ID,conditionType,condition) %>%  #按被试与条件分组
summarise(
avg_rt = mean(rt, na.rm = TRUE), sd_rt=sd(rt, na.rm = TRUE),
max_rt = max(rt, na.rm = TRUE), min_rt = min(rt, na.rm = TRUE),
all_count=n(),correct_count = sum(correct == 1 & rt>=200 & rt <=1200, na.rm = TRUE),
row_count = sum(rt>=200 & rt <=1200, na.rm = TRUE),
acc = correct_count /all_count ,#计算每个被试在每个条件的正确率= 正确/总数
)%>%
mutate(condition= case_when(
condition == "diamond" ~ "菱形",
condition == "square"~ "方形",
condition == "triangle" ~ "三角",
condition == "ellipse" ~ "椭圆",
condition== "hexagon"~ "六边",
condition == "diamond" ~ "菱形",
condition == "pentagon"~ "五边",
condition == "trapezoid" ~ "梯形",
condition == "circle" ~ "圆形",
)) %>%mutate(conditionType = case_when(
conditionType == "match" ~ "匹配",
conditionType == "nonmatch"~ "不匹配",
))
print(ALT1_data)
# ACC plot
acc_plot <- ggplot(ALT1_data, aes(x = condition, y = acc, fill = conditionType, colour = conditionType)) +
geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2, trim = FALSE, alpha = 0.5) +
geom_point(position = position_jitter(width = .15), size = .25, alpha = 0.5) +
geom_boxplot(aes(x = condition, y = acc), outlier.shape = NA, alpha = 0.5, width = .1, colour = "BLACK") +
ylab('正确率') + xlab('图形') + coord_flip() +
theme_cowplot() + guides(fill = FALSE, colour = FALSE) +
scale_colour_manual(values = colors) +#palette = "Dark2"
scale_fill_manual(values = colors) +#palette = "Dark2"
ggtitle("Figure 1a: ACC of ALT1")
# + guides(fill = guide_legend(title = "条件"), colour = guide_legend(title = "条件"))
# RT plot
rt_plot <- ggplot(ALT1_data, aes(x = condition, y = avg_rt, fill = conditionType, colour = conditionType)) +
geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2, trim = FALSE, alpha = 0.5) +
geom_point(position = position_jitter(width = .15), size = .25, alpha = 0.5) +
geom_boxplot(aes(x = condition, y = avg_rt), outlier.shape = NA, alpha = 0.5, width = .1, colour = "BLACK") +
ylab('反应时（ms）') + xlab(' ') + coord_flip() +#
theme_cowplot() + guides(fill = FALSE, colour = FALSE) +
scale_colour_manual(values = colors) +
scale_fill_manual(values = colors) +
ggtitle("Figure 1b: RT of ALT1")+
guides(fill = guide_legend(title = "条件"), colour = guide_legend(title = "条件"))
# Combine plots vertically
final_plot <- acc_plot | rt_plot
#ggsave(output_file, final_plot, width = 10, height = 15) #输出保存到文件夹
print(final_plot)
ggsave("fig2_ALT1.png", final_plot, width = 10, height = 8, dpi = 300)
#**图形x匹配/不匹配的反应时和正确率的方差分析**
ALT1_ACC <-ALT1_data%>%
MANOVA(., dv = "acc", subID="ID",
within=c("conditionType", "condition"),
sph.correction="GG",
file = "ALT1_ACC.doc") %>%
EMMEANS("conditionType", by = "condition")
ALT1_RT <-ALT1_data%>%
MANOVA(., dv = "avg_rt", subID="ID",
within=c("conditionType", "condition"),
sph.correction="GG",
file = "ALT1_RT.doc") %>%
EMMEANS("conditionType", by = "condition")
#*
#*
ALT1_data2 <- data%>%
group_by(ID,conditionType,condition) %>%  #按被试与条件分组
summarise(
avg_rt = mean(rt, na.rm = TRUE), sd_rt=sd(rt, na.rm = TRUE),
max_rt = max(rt, na.rm = TRUE),min_rt = min(rt, na.rm = TRUE),
all_count=n(),row_count = sum(rt>=200 & rt <=1200, na.rm = TRUE),
correct_count = sum(correct == 1 & rt>=200 & rt <=1200, na.rm = TRUE),acc = correct_count /all_count ,
)%>%
group_by(conditionType,condition)%>%
reframe( mean_rt= mean(avg_rt),  se_rt=sd(avg_rt) / sqrt(length(avg_rt)),
mean_acc=mean(acc), se_acc=sd(acc)/sqrt(length(acc))
)
print(ALT1_data2)
ALT1_plot_rt <- ALT1_data2%>%
ggplot(., aes(x = condition, y = mean_rt, fill = conditionType)) +
geom_bar(stat = "identity", position = position_dodge()) +
geom_errorbar(aes(ymin = mean_rt - se_rt, ymax = mean_rt + se_rt), position = position_dodge(width = 0.8), width = 0.25)+
geom_text(
aes(label = round(mean_rt)),  # Add labels rounded to the nearest integer
position = position_dodge(width = 0.8),
vjust = -0.8,  # Adjust vertical position of labels
size = 3  # Adjust label size if needed
)+
scale_fill_grey(start = 0.3) +
scale_y_continuous(limits = c(0, 900), breaks = seq(0, 900, 50), expand = c(0, 0)) +
guides(fill = guide_legend(title = "Identity"))+
theme_minimal()  +
labs(
x = "condition",
y = "RT",
title = "RT of ALT1 in Different condition",
caption = "Error bars indicate a standard error"
)  +
theme(
plot.title = element_text(size = 20,
face = "bold",
margin = margin(b = 35)),
axis.line = element_line(color = "#3D4852"),
axis.ticks = element_line(color = "#3D4852"),
panel.grid.major.y = element_line(color = "#DAE1E7"),
panel.grid.major.x = element_blank(),
panel.grid.minor.y = element_blank()
)
print(ALT1_plot_rt)
ALT1_plot_ACC <- ALT1_data2%>%
ggplot(., aes(x = condition, y = mean_acc, fill = conditionType)) +
geom_bar(stat = "identity", position = position_dodge(), na.rm = TRUE) +
geom_errorbar(aes(ymin = mean_acc - se_acc, ymax = mean_acc + se_acc), position = position_dodge(width = 0.8), width = 0.25)+
geom_text(
aes(label = round(mean_acc, digits = 2)),  # Add labels rounded to the nearest integer
position = position_dodge(width = 0.6),
vjust = -0.8,  # Adjust vertical position of labels
size = 3  # Adjust label size if needed
)+
scale_fill_grey(start = 0.3) +
scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1),expand = c(0, 0.1)) +
guides(fill = guide_legend(title = "Identity"))+
theme_minimal()  +
labs(
x = "condition",
y = "ACC",
title = "ACC of ALT1 in Different condition",
caption = "Error bars indicate a standard error"
)  +
theme(
plot.title = element_text(size = 20,
face = "bold",
margin = margin(b = 35)),
axis.line = element_line(color = "#3D4852"),
axis.ticks = element_line(color = "#3D4852"),
panel.grid.major.y = element_line(color = "#DAE1E7"),
panel.grid.major.x = element_blank(),
panel.grid.minor.y = element_blank()
)
print(ALT1_plot_ACC)
}
ALT1_analysis(ALT1_all)
write.csv(centrality$edge.betweenness.centrality,"edge.betweenness.centrality.csv")
centrality <- centrality_auto(aen_glasso_q, weighted = TRUE, signed = TRUE)
nc <- centrality$node.centrality #node centrality
nc
SPL <- centrality$ShortestPathLengths #shortest path length
SPL
write.csv(SPL,"SPL.csv")
write.csv(nc,"nc.csv")
View(task_q)
bruceR::Corr(task_q,
method = "spearman",#"pearson" (default), "spearman", or "kendall".
p.adjust = "none",#"none", "fdr", "holm", "bonferroni
all.as.numeric = TRUE,
digits = 2,
file = "cor_task_q.doc",#File name of MS Word (.doc).
plot = TRUE,
plot.r.size = 1.5,
plot.colors=c("#b2182b", "white", "#2166ac"),
plot.file = "cor_task_q.png",
plot.dpi = 500)
View(task_q)
