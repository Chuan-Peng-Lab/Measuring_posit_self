---
title: "SRET"
output: html_notebook
---

## SRET
## SRET的评估阶段按键“yes”，RT
```{r SRET EW}
SRET_EW<-function(data){
  
  # EW阶段的数据
SRET_EW<-data %>%
  mutate(ID = as.character(ID)) %>%
  mutate(rt=as.numeric(rt))%>% #转变被试编号和反应时类型为字符型与数值型
  mutate(correct= as.numeric(correct))%>% ##重编码correct
  filter(screen_id%in%c("EW_formal") )%>% #选择正式实验的数据
   filter(!word %in% c("务实", "迷糊", "坚贞", "说谎", "主见", "缓慢", "素养", "低俗")) #筛除练习词
 
 #每个被试在 person(self,friend) * valence(positive,negative) * domain(ability,moral)的词汇评估的按'yes'比例                          
SRET_EW<-SRET_EW%>%
  group_by(ID,person,valence,domain)%>%
  summarize(N_Yes = sum(responses == "yes"),
            N_No = sum(responses == "no"),
            N=n(),
            pro_yes=N_Yes/N,
            avg_rt = mean(rt, na.rm = TRUE),
            sd_rt=sd(rt, na.rm = TRUE),
           )
print(SRET_EW)
a<-describe(SRET_EW)
print(a)



 # 领域（道德，能力）*参照（我，朋友）*效价（积极，消极），方差分析，yes比例
SRET_EW_ANOVA<-SRET_EW%>%
MANOVA(.,
       subID="ID",
       dv="pro_yes",    # 认为词汇描述了参照对象的比例
       within=c("domain","person","valence"),)%>% 
# EMMEANS("valence", by="domain") %>%
 # EMMEANS("person", by="domain") %>%
 #  EMMEANS("person", by="valence") %>%
  EMMEANS(c("valence", "person"), by="domain") %>%
  EMMEANS("person", by=c("domain", "valence")) 
print(SRET_EW_ANOVA)

 # 领域（道德，能力）*参照（我，朋友）*效价（积极，消极），方差分析，rt
SRET_EW_ANOVA2<-SRET_EW%>%
MANOVA(.,
       subID="ID",
       dv="avg_rt",    # 认为词汇描述了参照对象的比例
       within=c("domain","person","valence"),)%>% 
# EMMEANS("valence", by="domain") %>%
 # EMMEANS("person", by="domain") %>%
  # EMMEANS("person", by="valence") %>%
  EMMEANS(c("valence", "person"), by="domain") %>%
  EMMEANS("person", by=c("domain", "valence")) 
print(SRET_EW_ANOVA2)

 # 评估词按yes的比例
   pro_yes_EW <- SRET_EW %>%
    ggplot(., aes(x = valence, y = pro_yes, fill = person, colour = person)) +
    geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2, trim = FALSE, alpha = 0.5) +
    geom_point(position = position_jitter(width = .15), size = .25, alpha = 0.5) +
    geom_boxplot(aes(x = valence, y = pro_yes), outlier.shape = NA, alpha = 0.5, width = .1, colour = "BLACK") +
    ylab('pro_yes') + xlab('valence') + coord_flip() +
    theme_cowplot() + guides(fill = FALSE, colour = FALSE) +
     facet_wrap(~domain)+
    scale_colour_brewer(palette = "Dark2") +
    scale_fill_brewer(palette = "Dark2") +
    ggtitle("Figure 1a: pro_yes of SRET_EW")+
  guides(fill = guide_legend(title = "condition"), colour = guide_legend(title = "condition"))

 print(pro_yes_EW)
  
  ###############################
  # 评估阶段rt plot
  rt_EW_rt <- SRET_EW %>%
    ggplot(., aes(x = valence, y = avg_rt, fill = person, colour = person)) +
    geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2, trim = FALSE, alpha = 0.5) +
    geom_point(position = position_jitter(width = .15), size = .25, alpha = 0.5) +
    geom_boxplot(aes(x = valence, y = avg_rt), outlier.shape = NA, alpha = 0.5, width = .1, colour = "BLACK") +
    ylab('RT') + xlab('valence') + coord_flip() +
    theme_cowplot() + guides(fill = FALSE, colour = FALSE) +
     facet_wrap(~domain)+
    scale_colour_brewer(palette = "Dark2") +
    scale_fill_brewer(palette = "Dark2") +
    ggtitle("Figure 1a: RT of SRET_EW")+
  guides(fill = guide_legend(title = "condition"), colour = guide_legend(title = "condition"))

 
  print(rt_EW_rt)
  
  
  
 
}
SRET_EW(SRET)
```

```{r 计算题}
SRET_math<-function(data){
  
  # EW阶段的yes比例和rt汇总
SRET_math<-data %>%
  mutate(ID = as.character(ID)) %>%
  mutate(rt=as.numeric(rt))%>% #转变被试编号和反应时类型为字符型与数值型
  mutate(correct= as.numeric(correct))%>% ##重编码correct
  filter(screen_id%in%c("SRET_math_calculate") )%>% #选择正式实验的数据
  group_by(ID)%>%
  summarize(total_rt = sum(rt, na.rm = TRUE),
    n_correct = sum(correct == "1"),
            N=n(),
            mean_rt=mean(rt, na.rm = TRUE),
acc=n_correct/N  )
print(SRET_math)
print(describe(SRET_math))


rt_SRET_math <- ggplot(SRET_math, aes(x = mean_rt)) +
  geom_density(fill = "skyblue", alpha = 0.7) +
  labs(title = "Density Plot of mean_rt",
       x = "mean_rt") +
  theme_minimal()

# 绘制acc的概率密度分布图
acc_SRET_math <-ggplot(SRET_math, aes(x = acc)) +
  geom_density(fill = "lightcoral", alpha = 0.7) +
  labs(title = "Density Plot of acc",
       x = "acc") +
  theme_minimal()

  print(rt_SRET_math/acc_SRET_math)


}
SRET_math(SRET)
```

### SRET第一步新旧词判断
```{r SRET RJ_formal1}
SRET_RJ <- function(data) {
  #############新旧词再认数据
  SRET_RJ <- data %>%
    mutate(ID = as.character(ID),
           rt = as.numeric(rt),
           correct = as.numeric(correct)) %>%
    filter(screen_id %in% c("RJ_formal1")) %>%
    filter(!word %in% c("严谨", "认真", "刻板", "白痴", "忠实", "宽宏", "徇私", "可鄙")) %>%
    mutate(sdt = case_when((identity == "old" & (responses %in% c("familiar", "old"))) ~ "hit",
                          (identity == "old" & (responses == "new" )) ~ "miss",
                          (identity == "new" & (responses %in% c("familiar", "old"))) ~ "fa",
                          (identity == "new" & (responses == "new")) ~ "cr"),) 
   ################新旧词判断的反应时
   SRET_RJ_rt <- SRET_RJ %>%
     group_by(ID,domain,valence,person) %>%#, valence
    summarize(
      avg_rt = mean(rt, na.rm = TRUE),
      sd_rt = sd(rt, na.rm = TRUE),
      max_rt = max(rt, na.rm = TRUE),
    min_rt = min(rt, na.rm = TRUE),
    )%>%
    ggplot(., aes(x = valence, y = avg_rt, fill = person, colour = person)) +
    geom_flat_violin(position = position_nudge(x = .25, y = 0), adjust = 2, trim = FALSE, alpha = 0.5) +
    geom_point(position = position_jitter(width = .15), size = .25, alpha = 0.5) +
    geom_boxplot(aes(x = valence, y = avg_rt), outlier.shape = NA, alpha = 0.5, width = .1, colour = "BLACK") +
    ylab('RT') + xlab('valence') + coord_flip() +
    theme_cowplot() + guides(fill = FALSE, colour = FALSE) +
     facet_wrap(~domain)+
    scale_colour_brewer(palette = "Dark2") +
    scale_fill_brewer(palette = "Dark2") +
    ggtitle("Figure 1a: RT of SRET_RJ")+
  guides(fill = guide_legend(title = "condition"), colour = guide_legend(title = "condition"))
   print(SRET_RJ_rt)
###########计算每个被试的总再认正确率#####
 SRET_RJ.1 <- SRET_RJ %>%
    group_by(ID) %>%#, valence
    summarize(
      H = sum(sdt == "hit"),
      M = sum(sdt == "miss"),
      FA = sum(sdt == "fa"),
      CR = sum(sdt == "cr"),
      new= sum(responses %in% c("new")),#按键为新词
      old=sum(responses %in% c("old")),
      familiar=sum(responses %in% c("familiar")),
     self_H = sum(sdt == "hit"& person=="self"),
     friend_H = sum(sdt == "hit"& person=="friend"),
     P_H = H/(H+M),
     P_FA = FA/(FA+CR),
      recognition = (H + CR) / (H + CR + M + FA),### valence * domain,4个条件 *（20 new+ 20 old）, 20 old = 10 self +10 friend
      avg_rt = mean(rt, na.rm = TRUE),
      sd_rt = sd(rt, na.rm = TRUE),
      max_rt = max(rt, na.rm = TRUE),
    min_rt = min(rt, na.rm = TRUE),
    ) %>%
    mutate(
     # if hit rate is 1, standardize it  P_H = ifelse(P_H == 1, 1 - 1 / (2 * (H + M)), P_H),
   # if FA rate is 0, standardize it   P_FA = ifelse(P_FA == 0, 1 / (2 * (H + M)), P_FA), 
      P_H = (H+0.5)/(H+M+1),# log correction
     P_FA = (FA+0.5)/(FA+CR+1),# log correction
      Correct_recognition = P_H - P_FA,
      Z_P_H = qnorm(P_H),
      Z_P_FA = qnorm(P_FA),
      d_prime = Z_P_H - Z_P_FA,
      note = ifelse(recognition<0.55, "invalid", "valid")) 
   
 invalid_SRET_RJ<-SRET_RJ.1%>%
filter(note == "invalid") #再认正确率低于0.55的被试
  print(invalid_SRET_RJ)
   
   a<-describe(SRET_RJ.1)
   print(a)
   
   
   
  #用于方差分析的数据 
    SRET_RJ <- SRET_RJ %>%
   # filter(!ID %in% invalid_SRET_RJ$ID)%>%
    group_by(ID,domain,valence) %>%#, valence
    summarize(
      H = sum(sdt == "hit"),
      M = sum(sdt == "miss"),
      FA = sum(sdt == "fa"),
      CR = sum(sdt == "cr"),
      new= sum(responses %in% c("new")),#按键为新词
      old=sum(responses %in% c("old")),
      familiar=sum(responses %in% c("familiar")),

     P_H = (H+0.5)/(H+M+1),# log correction
     P_FA = (FA+0.5)/(FA+CR+1),# log correction
      recognition = (H + CR) / (H + CR + M + FA),### valence * domain,4个条件 *（20 new+ 20 old）, 20 old = 10 self +10 friend
      avg_rt = mean(rt, na.rm = TRUE),
      sd_rt = sd(rt, na.rm = TRUE),
      max_rt = max(rt, na.rm = TRUE),
    min_rt = min(rt, na.rm = TRUE),
    ) %>%
    mutate(
     # P_H = ifelse(P_H == 1, 1 - 1 / (2 * (H + M)), P_H),# if hit rate is 1, standardize it
     # P_FA = ifelse(P_FA == 0, 1 / (2 * (H + M)), P_FA), # if FA rate is 0, standardize it
      
      Correct_recognition = P_H - P_FA,
      Z_P_H = qnorm(P_H),
      Z_P_FA = qnorm(P_FA),
      d_prime = Z_P_H - Z_P_FA) 
 
   print(SRET_RJ)
   a<-describe(SRET_RJ)
   print(a)
   
   assign("SRET_RJ", SRET_RJ, envir = .GlobalEnv)
   
###### 计算总体的统计值####################
 SRET_RJ_rt <- data %>%
    mutate(ID = as.character(ID),
           rt = as.numeric(rt),
           correct = as.numeric(correct)) %>%
      #filter(!ID %in% invalid_SRET_RJ$ID)%>%####
    filter(screen_id %in% c("RJ_formal1")) %>%
    filter(!word %in% c("严谨", "认真", "刻板", "白痴", "忠实", "宽宏", "徇私", "可鄙")) %>%
    mutate(sdt = case_when((identity == "old" & (responses %in% c("familiar", "old"))) ~ "hit",
                          (identity == "old" & (responses == "new" )) ~ "miss",
                          (identity == "new" & (responses %in% c("familiar", "old"))) ~ "fa",
                          (identity == "new" & (responses == "new")) ~ "cr"),) %>%
   select(-ID)%>%
    group_by(domain, valence ) %>%#, valence
    summarize(
      all_H = sum(sdt == "hit"),
      all_M = sum(sdt == "miss"),
      all_FA = sum(sdt == "fa"),
      all_CR = sum(sdt == "cr"),
      all_new= sum(responses %in% c("new")),#按键为新词
      all_old=sum(responses %in% c("old")),
      all_familiar=sum(responses %in% c("familiar")),
   
all_recognition = (all_H + all_CR)/(all_H + all_CR + all_M + all_FA),## valence * domain,4个条件 *（20 new+ 20 old）,20 old = 10 self +10 friend
      avg_rt_mean = mean(rt, na.rm = TRUE),
      avg_sd_rt = sd(rt, na.rm = TRUE),
      all_max_rt = max(rt, na.rm = TRUE),
    all_min_rt = min(rt, na.rm = TRUE),
    ) %>%  ##
    mutate(      
      all_P_H = (all_H+0.5)/(all_H+all_M+1),
     all_P_FA = (all_FA+0.5)/(all_FA+all_CR+1),
     # all_P_H = ifelse(all_P_H == 1, 1 - 1 / (2 * (all_H + all_M)),all_P_H),# 1/(2N) rule;if hit rate is 1, standardize it
     # all_P_FA = ifelse(all_P_FA == 0, 1 / (2 * (all_H + all_M)), all_P_FA), #1/(2N) rule; if FA rate is 0, standardize it
      all_Correct_recognition = all_P_H - all_P_FA,

      all_d_prime = qnorm(all_P_H) -qnorm(all_P_FA) ) 
print(SRET_RJ_rt)
 ###################排除被试，反应时在3个标准差以外，再认正确率小于等于0.5，矫正的正确率是负######################## 
SRET_RJ_subj<- SRET_RJ%>%
  left_join(SRET_RJ_rt, by = c("valence", "domain"))%>% 
  filter(avg_rt < avg_rt_mean - 3 * avg_sd_rt | avg_rt > avg_rt_mean + 3 * avg_sd_rt|recognition<=0.5|Correct_recognition<0|d_prime<0) 

print(SRET_RJ_subj)
assign("SRET_RJ_subj", SRET_RJ_subj, envir = .GlobalEnv)

SRET_RJ_ID<-unique(SRET_RJ_subj$ID)
print(SRET_RJ_ID)
###########################################################
   
    SRET_RJ_plot2 <- SRET_RJ %>% 
    ggplot(.,aes(x=valence,y=recognition, fill =valence, colour =valence))+
  geom_flat_violin(position = position_nudge(x = .25, y = 0),adjust =2, trim = FALSE)+
  geom_point(position = position_jitter(width = .15), size = .25)+
  geom_boxplot(aes(x =valence, y =recognition),outlier.shape = NA, alpha = 0.3, width = .1, colour = "BLACK") +
ylab('recognition')+xlab('condition')+coord_flip()+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
 facet_wrap(~domain)+
  scale_colour_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ggtitle("Figure 10: recognition of SRET_RJ ")
    print(SRET_RJ_plot2)
    
     SRET_RJ_plot3 <- SRET_RJ %>% 
    ggplot(.,aes(x=valence,y=d_prime, fill =valence, colour =valence))+
  geom_flat_violin(position = position_nudge(x = .25, y = 0),adjust =2, trim = FALSE)+
  geom_point(position = position_jitter(width = .15), size = .25)+
  geom_boxplot(aes(x =valence, y =d_prime),outlier.shape = NA, alpha = 0.3, width = .1, colour = "BLACK") +
ylab('d_prime')+xlab('condition')+coord_flip()+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
 facet_wrap(~domain)+
  scale_colour_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ggtitle("Figure 11: d_prime of SRET_RJ ")
    print(SRET_RJ_plot3)
    
    # rt的方差分析
    SRET_RJ_ANOV<-SRET_RJ%>%
      MANOVA(.,subID="ID",dv="avg_rt",
       within=c("domain","valence"))%>%
 EMMEANS("valence", by="domain") %>%
  EMMEANS("domain", by="valence")
    print(SRET_RJ_ANOV)
    
    # recognition的方差分析
     SRET_RJ_ANOV2<-SRET_RJ%>%
      MANOVA(.,subID="ID",dv="recognition",
       within=c("domain","valence"))%>%
 EMMEANS("valence", by="domain") %>%
  EMMEANS("domain", by="valence")
     print(SRET_RJ_ANOV2)
     
    # Correct_recognition的方差分析 
 SRET_RJ_ANOV3<-SRET_RJ%>%
      MANOVA(.,subID="ID",dv="Correct_recognition",
       within=c("domain","valence"))%>%
 EMMEANS("valence", by="domain") %>%
  EMMEANS("domain", by="valence")
     print(SRET_RJ_ANOV3)
   # d_prime的方差分析  
     SRET_RJ_ANOV4<-SRET_RJ%>%
      MANOVA(.,subID="ID",dv="d_prime",
       within=c("domain","valence"))%>%
 EMMEANS("valence", by="domain") %>%
  EMMEANS("domain", by="valence")
     print(SRET_RJ_ANOV4)
     
}

# 调用函数并存储结果
SRET_RJ(SRET)
```

### SRET第二步词汇来源判断
```{r SRET RJ_formal2_source_memory}
SRET_Source_M<-function(data){
SRET_RJ_2 <- data %>%
  mutate(ID = as.character(ID)) %>%
  mutate(rt = as.numeric(rt)) %>%
 mutate(correct = as.numeric(coalesce(correct,-1))) %>% #对新词按键判断的试次的correct记为-1
  filter(screen_id %in% c("RJ_formal_2")) %>%
  filter(!word %in% c("严谨", "认真", "刻板", "白痴", "忠实", "宽宏", "徇私", "可鄙")) %>%
   mutate(sdt = case_when((identity == "self" & (correct=="1") )~ "self_hit",
                          #自我条件下的击中，信号是“self”，反应是“self”
                          (identity == "self" & (correct=="0") )~ "self_miss",
                          #自我条件下的漏报，信号是“self”，反应是“friend”
                          (identity == "friend" & (correct=="1" )) ~ "friend_hit",
                          #朋友条件下的击中，信号是“friend”，反应是“friend”
                           (identity == "friend" & (correct=="0" )) ~ "friend_miss",
                          #朋友条件下的漏报，信号是“friend”，反应是“self”
                          (is.na(identity) & (!is.na(response))) ~ "fa",
                          #新词（无信号），反应为self或者friend
                        ) )
print(SRET_RJ_2)

SRET_RJ_check<-SRET_RJ_2%>%
  group_by(ID) %>% #每个被试在效价*领域 的条件
  summarize(
    n=n(), #所有按键反应了的试次
     row_count = sum(rt<200, na.rm = TRUE),
    less_200=row_count/n,
   count_self = sum(responses == "self"),#所有反应是“self”的试次
   count_friend = sum(responses == "friend"),#所有反应是“friend”的试次
   self_H = sum(sdt == "self_hit"),#自我条件下的击中，信号是“self”，反应是“self”
   friend_H = sum(sdt == "friend_hit"),#朋友条件下的击中，信号是“friend”，反应是“friend”
    self_M = 10-self_H,# 信号为self，没有被反应为“self
   friend_M = 10-friend_H, # 信号为friend，没有被反应为“friend
      FA = sum(sdt == "fa"),#新词（无信号），反应为self或者friend
      CR = 20-FA,#总共20新词，去掉被判断为旧词（信号），正确拒绝旧词
      self_recognition = self_H /count_self,
   # number of correct source attributions for self/ number of hits for self
   friend_recognition = friend_H/ count_friend,
      avg_rt = mean(rt, na.rm = TRUE),
      sd_rt = sd(rt, na.rm = TRUE),
   max_rt = max(rt, na.rm = TRUE),
    min_rt = min(rt, na.rm = TRUE),
  )
print(SRET_RJ_check)

SRET_RJ_2<-SRET_RJ_2%>%
  group_by(ID,valence,domain) %>% #每个被试在效价*领域 的条件
  summarize(
    n=n(), #所有按键反应了的试次
     row_count = sum(rt<200, na.rm = TRUE),
    less_200=row_count/n,
   count_self = sum(responses == "self"),#所有反应是“self”的试次
   count_friend = sum(responses == "friend"),#所有反应是“friend”的试次
   self_H = sum(sdt == "self_hit"),#自我条件下的击中，信号是“self”，反应是“self”
   friend_H = sum(sdt == "friend_hit"),#朋友条件下的击中，信号是“friend”，反应是“friend”
    self_M = 10-self_H,# 信号为self，没有被反应为“self
   friend_M = 10-friend_H, # 信号为friend，没有被反应为“friend
      FA = sum(sdt == "fa"),#新词（无信号），反应为self或者friend
      CR = 20-FA,#总共20新词，去掉被判断为旧词（信号），正确拒绝旧词
      self_recognition = self_H /count_self,
   # number of correct source attributions for self/ number of hits for self
   friend_recognition = friend_H/ count_friend,
      avg_rt = mean(rt, na.rm = TRUE),
      sd_rt = sd(rt, na.rm = TRUE),
   max_rt = max(rt, na.rm = TRUE),
    min_rt = min(rt, na.rm = TRUE),
  )
print(SRET_RJ_2)

########################################
# 使用group_by和summarize检查每个ID的行数
id_counts <- SRET_RJ_2 %>%
  ungroup()%>%
  group_by(ID) %>%
  summarize(row_count = n())

# 检查是否每个ID都有4行数据
all_ids_have_four_rows <- all(id_counts$row_count == 4)
select_subj<- id_counts %>%
  filter(row_count != 4) %>%
  pull(ID)
print(select_subj)
assign("select_subj", select_subj, envir = .GlobalEnv)

SRET_RJ_2rt<-data %>%
  mutate(ID = as.character(ID)) %>%
  mutate(rt = as.numeric(rt)) %>%
 mutate(correct = as.numeric(coalesce(correct,-1))) %>% #对新词按键判断的试次的correct记为-1
  filter(screen_id %in% c("RJ_formal_2")) %>%
  filter(!word %in% c("严谨", "认真", "刻板", "白痴", "忠实", "宽宏", "徇私", "可鄙")) %>%
   mutate(sdt = case_when((identity == "self" & (correct=="1") )~ "self_hit",
                          #自我条件下的击中，信号是“self”，反应是“self”
                          (identity == "self" & (correct=="0") )~ "self_miss",
                          #自我条件下的漏报，信号是“self”，反应是“friend”
                          (identity == "friend" & (correct=="1" )) ~ "friend_hit",
                          #朋友条件下的击中，信号是“friend”，反应是“friend”
                           (identity == "friend" & (correct=="0" )) ~ "friend_miss",
                          #朋友条件下的漏报，信号是“friend”，反应是“self”
                          (is.na(identity) & (!is.na(response))) ~ "fa",
                          #新词（无信号），反应为self或者friend
                        ) )%>%
  group_by(valence,domain) %>% #效价*领域 条件的再认正确率
  summarize(
    all_n=n(), #所有按键反应了的试次
   all_count_self = sum(responses == "self"),#所有反应是“self”的试次
   all_count_friend = sum(responses == "friend"),#所有反应是“friend”的试次
   all_self_H = sum(sdt == "self_hit"),#自我条件下的击中，信号是“self”，反应是“self”
   all_friend_H = sum(sdt == "friend_hit"),#朋友条件下的击中，信号是“friend”，反应是“friend”
    all_self_M = 10-all_self_H,# 信号为self，没有被反应为“self
   all_friend_M = 10-all_friend_H, # 信号为friend，没有被反应为“friend
      all_FA = sum(sdt == "fa"),#新词（无信号），反应为self或者friend
      all_CR = 20-all_FA,#总共20新词，去掉被判断为旧词（信号），正确拒绝旧词
      all_self_recognition = all_self_H /all_count_self,
   # number of correct source attributions for self/ number of hits for self
   all_friend_recognition = all_friend_H/ all_count_friend,
      avg_rt_mean = mean(rt, na.rm = TRUE),
      avg_sd_rt = sd(rt, na.rm = TRUE),
   all_max_rt = max(rt, na.rm = TRUE),
    all_min_rt = min(rt, na.rm = TRUE),
  )%>%
  pivot_longer(cols = c(all_self_recognition, all_friend_recognition),
               names_to = "person",
               values_to = "all_recognition")%>%
  mutate(person = case_when(
    person == "all_self_recognition" ~ "self",
    person == "all_friend_recognition" ~ "friend",
  ))            
print(SRET_RJ_2rt)

#########################################


SRET_RJ_2<-SRET_RJ_2%>%
  pivot_longer(cols = c(self_recognition, friend_recognition),
               names_to = "person",
               values_to = "recognition")%>%
  mutate(person = case_when(
    person == "self_recognition" ~ "self",
    person == "friend_recognition" ~ "friend",#效价*领域 条件在self和friend的再认正确率
  ))                   
print(SRET_RJ_2)

SRET_RJ_2_subj<- SRET_RJ_2%>%
  left_join(SRET_RJ_2rt, by = c("person","valence", "domain"))%>% 
  filter(avg_rt < avg_rt_mean - 3 * avg_sd_rt | avg_rt > avg_rt_mean + 3 * avg_sd_rt|recognition<0.1) %>%
  select(ID,person,valence,domain,avg_rt,avg_rt_mean,recognition,all_recognition,)
print(SRET_RJ_2_subj)
SRET_RJ_2_ID<-unique(SRET_RJ_2_subj$ID)
print(SRET_RJ_2_ID)
assign("SRET_RJ_2_subj", SRET_RJ_2_subj, envir = .GlobalEnv)


 SRET_RJ2_plot <- SRET_RJ_2 %>% 
    ggplot(.,aes(x=person,y=recognition, fill =valence, colour =valence))+
  geom_flat_violin(position = position_nudge(x = .25, y = 0),adjust =2, trim = FALSE, alpha = 0.5)+
  geom_point(position = position_jitter(width = .15), size = .25, alpha = 0.5)+
  geom_boxplot(aes(x =person, y =recognition),outlier.shape = NA, alpha = 0.5, width = .1, colour = "BLACK") +
ylab('ACC')+xlab('condition')+coord_flip()+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
 facet_wrap(~domain)+
  scale_colour_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ggtitle("Figure 10: acc of SRET_RJ ")+
  guides(fill = guide_legend(title = "Valence"), colour = guide_legend(title = "Valence"))
   
   print(SRET_RJ2_plot)
   
   SRET_RJ2_plot2 <- SRET_RJ_2 %>% 
    ggplot(.,aes(x=person,y=avg_rt, fill =valence, colour =valence))+
  geom_flat_violin(position = position_nudge(x = .25, y = 0),adjust =2, trim = FALSE, alpha = 0.5)+
  geom_point(position = position_jitter(width = .15), size = .25, alpha = 0.5)+
  geom_boxplot(aes(x =person, y =avg_rt),outlier.shape = NA, alpha = 0.3, width = .1, colour = "BLACK") +
ylab('rt')+xlab('condition')+coord_flip()+theme_cowplot()+guides(fill = FALSE, colour = FALSE) +
 facet_wrap(~domain)+
  scale_colour_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ggtitle("Figure 11: RT of SRET_RJ ")+
  guides(fill = guide_legend(title = "Valence"), colour = guide_legend(title = "Valence"))
   
   print(SRET_RJ2_plot2)
   
 

}
SRET_Source_M(SRET)
```


# MPT

```{r}
#-----Study 1 - MPT modeling analysis

#load required packages

install.packages("TreeBUGS")

library(TreeBUGS)


#input data


SRET_RJ_2_ability <- SRET%>%
  mutate(ID = as.character(ID)) %>% #改为字符型
  mutate(rt = as.numeric(rt)) %>% #改为数值型
   filter(screen_id %in% c("RJ_formal1","RJ_formal_2")) %>%  #筛选出再认阶段
  filter(!word %in% c("严谨", "认真", "刻板", "白痴", "忠实", "宽宏", "徇私", "可鄙"))%>% #筛除练习阶段的词语
   mutate(
    identity = ifelse(screen_id == "RJ_formal1" &responses == "new" & identity == "old" & grepl("friend", con), "friend", identity),#item is friend,response is new
    identity = ifelse(screen_id == "RJ_formal1" &responses == "new" & identity == "old" & grepl("self", con), "self", identity)# item is self ,response is new
  )%>%
  mutate(identity = ifelse(screen_id == "RJ_formal_2" & is.na(identity), "new", identity)) %>%#再认第二阶段刺激分类不是self也不是friend的，重编码为new
  filter(valence == "Positive" & domain == "ability") %>% #选择能力领域的积极词汇；选择道德领域valence == "Positive" & domain == "moral";查看消极词valence == "Negative" & domain == "ability"；valence == "Negative" & domain == "moral"
  select(ID,valence,domain,screen_id,identity,response,responses,con)%>%#选择identity（item type），responses（response type),con（condition， e.g.friend_Negative_morality)
  group_by(ID) %>%
  summarize(n=n(),
    SG_SG = sum(identity == "self" & (responses=="self")),# SG_SG response "self" to a self item
    SG_NSG = sum(identity == "self" & (responses=="friend")),# SG_NSG response "friend" to a self item
    SG_Nw = sum(identity == "self" & (responses=="new")),# SG_Nw response "new" to a self item
    NSG_SG = sum(identity == "friend" & (responses=="self")),# NSG_SG response "self" to a friend item
    NSG_NSG = sum(identity == "friend" & (responses=="friend")),# NSG_NSG response "friend" to a friend item
    NSG_Nw = sum(identity == "friend" & (responses=="new")),# NSG_Nw response "new" to a friend item
    Nw_SG = sum(identity == "new" & (responses=="self")),# Nw_SG response "self" to a new item
    Nw_NSG = sum(identity == "new" & (responses=="friend")),# Nw_NSG response "friend" to a new item
    Nw_Nw = sum(identity == "new" & (responses=="new")),# Nw_Nw response "new" to a new item
   
  )
print(SRET_RJ_2_ability)


###################################

#-----Test model assumption

#  item memory (D), source memory (d ), old–new guessing (guessing an item as studied, b), and source guessing (guessing an item as self with and without item memory, a and g, respectively).

#Define data frame
data_smt_ability <- SRET_RJ_2_ability[,3:ncol(SRET_RJ_2_ability)]#选择SG_SG:Nw_Nw列，每行是一个被试

#Base model --- Constraint: a=g, DNSG=DNw
base.model <- traitMPT(eqnfile="self_reference_MPT/model.eqn",#输入的模型
                     data = data_smt_ability,  #输入的模型使用的数据
                     restrictions = list("a = g", "DNSG = DNw"),#设置的限制条件
                     modelfilename = "2htsm_predictor.jags",#输出运行模型内使用的计算
                     transformedParameters = list("delta_D=DSG-DNSG", "delta_d=dSG-dNSG"),#输出结果的参数的转换
                     parEstFile = "results_base_model.txt",#输出的对每个被试的模型参数的结果文件
                     n.chain = 4, n.iter = 1000000, n.adapt = 500000,#模型拟合的参数设定
                     n.burnin = 500000, n.thin = 100,
                     ppp=1000)


#Final model --- Constraints: a=g, DNSG=DNw, dSG=dNSG
final.model <- traitMPT(eqnfile="self_reference_MPT/model.eqn",
                     data = data_smt_ability,
                     restrictions = list("a = g", "DNSG = DNw", "dSG=dNSG"),
                     modelfilename = "2htsm_predictor.jags",
                     parEstFile = "results_final_model.txt",
                     n.chain = 4, n.iter = 1000000, n.adapt = 500000,
                     n.burnin = 500000, n.thin = 100,
                     ppp=1000)


```




```{r 查看模型结果}
summary(base.model)
```
```{r 绘制模型结果的图}
plot(base.model)
```
```{r}
#输出每个被试的参数估计的结果到csv文件
getParam(base.model,
  parameter = "theta",
  stat = "summary", file = "MPT_parameter.csv"
)
```

```{r}
###################################
#**代完成，之后与各问卷总分做回归，问卷总分需要z-standardized**
#-----Latent-trait regression

#Define data frame
data_smt <- data[,1:9]
cov.std <- data[,10:11]
colnames(cov.std) <- c("recognition.std", "sharing.std")


#Final model --- Constraints: a=g, DNSG=DNw, dSG=dNSG
#Regression: Emotion recognition
final.model.recognition <- traitMPT(eqnfile="model/model.eqn",
                          data = data_smt,
                          restrictions = list("a = g", "DNSG = DNw", "dSG=dNSG"),
                          modelfilename = "2htsm_predictor.jags",
                          covData = cov.std,
                          predStructure = list("DSG DNSG dSG b g; recognition.std"),
                          parEstFile = "results_final_model_recognition.txt",
                          n.chain = 4, n.iter = 1000000, n.adapt = 500000,
                          n.burnin = 500000, n.thin = 100,
                          ppp=1000)


#Final model --- Constraints: a=g, DNSG=DNw, dSG=dNSG
#Regression: Emotion sharing
final.model.sharing    <- traitMPT(eqnfile="model/model.eqn",
                                   data = data_smt,
                                   restrictions = list("a = g", "DNSG = DNw", "dSG=dNSG"),
                                   modelfilename = "2htsm_predictor.jags",
                                   covData = cov.std,
                                   predStructure = list("DSG DNSG dSG b g; sharing.std"),
                                   parEstFile = "results_final_model_sharing.txt",
                                   n.chain = 4, n.iter = 1000000, n.adapt = 500000,
                                   n.burnin = 500000, n.thin = 100,
                                   ppp=1000)


###################################

#-----Latent-trait regression (with control variables)

#Handle missing data in sex
data[data[,c(1:12)] == 999] <- NA
data <- na.omit(data)

#Define data frame
data_smt <- data[,1:9]
cov.std <- data[,10:12]
colnames(cov.std) <- c("recognition.std", "sharing.std", "sex.std")


#Final model --- Constraints: a=g, DNSG=DNw, dSG=dNSG
#Regression: Emotion recognition with control variables
final.model.recognition.control <- traitMPT(eqnfile="model/model.eqn",
                                           data = data_smt,
                                           restrictions = list("a = g", "DNSG = DNw", "dSG=dNSG"),
                                           modelfilename = "2htsm_predictor.jags",
                                           covData = cov.std,
                                           predStructure = list("DSG DNSG dSG b g; recognition.std sex.std"),
                                           parEstFile = "results_final_model_recognition_control.txt",
                                           n.chain = 4, n.iter = 1000000, n.adapt = 500000,
                                           n.burnin = 500000, n.thin = 100,
                                           ppp=1000)


#Final model --- Constraints: a=g, DNSG=DNw, dSG=dNSG
#Regression: Emotion sharing with control variables
final.model.sharing.control <- traitMPT(eqnfile="model/model.eqn",
                                        data = data_smt,
                                        restrictions = list("a = g", "DNSG = DNw", "dSG=dNSG"),
                                        modelfilename = "2htsm_predictor.jags",
                                        covData = cov.std,
                                        predStructure = list("DSG DNSG dSG b g; sharing.std sex.std"),
                                        parEstFile = "results_final_model_sharing_control.txt",
                                        n.chain = 4, n.iter = 1000000, n.adapt = 500000,
                                        n.burnin = 500000, n.thin = 100,
                                        ppp=1000)
```

