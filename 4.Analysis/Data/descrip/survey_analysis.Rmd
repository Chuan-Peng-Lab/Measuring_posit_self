---
title: "survey_analysis"
output: html_document
date: "2023-12-15"
---
```{r}
#清空环境
rm(list = ls())
```

### 加载R包

```{r create environment}
# 检查是否已安装 pacman
if (!requireNamespace("pacman", quietly = TRUE)) {
  install.packages("pacman") }   # 如果未安装，则安装包

# 加载所需要的R包
pacman::p_load("tidyverse","openxlsx","here","tidyverse","bruceR","ggplot2","psych","psychTools","DataExplorer","lavaan","rstatix","jmv")
```

```{r}
day2_q <-read.csv("../../Data/all//day2_q_all.csv ")#修改phase_002
day0_q <-read.csv("../../Data/all//day0_all.csv ")#修改phase_002
day1_q<-read.csv("../../Data/all//day1_q_all.csv")#修改phase_002

#合并day0到day2的问卷数据
day0t2_q<- merge(day0_q, day1_q, by = "ID", all = TRUE) %>%
  merge(day2_q, by = "ID", all = TRUE)
# %>%filter(ID != "phase_002_subj_1" & ID != "phase_002_subj_3")#这行代码不是每次都需要，这是被试流失，去除流失的被试

#对合并day0到day2的问卷数据，进行总分计算
day0t2_q<- day0t2_q%>%
  mutate(
    phq_al = rowSums(select(., starts_with("phq")), na.rm = TRUE),
    gad_al = rowSums(select(., starts_with("gad")), na.rm = TRUE),
    selfclarity_al = rowSums(select(., starts_with("selfclarity")), na.rm = TRUE),
    ses_al = rowSums(select(., starts_with("ses")), na.rm = TRUE),
    coreself_al =rowSums(select(., starts_with("coreself")), na.rm = TRUE),
    SGPS_al = rowSums(select(., starts_with("SGPS")), na.rm = TRUE),
    hsns_al = rowSums(select(., starts_with("hsns")), na.rm = TRUE),
    NPI_al = rowSums(select(., starts_with("NPI")), na.rm = TRUE),
    swb_al = rowSums(select(., starts_with("swb")), na.rm = TRUE),
    LOT_al = rowSums(select(., starts_with("LOT")), na.rm = TRUE),
    sde_al= rowSums(select(., starts_with("sde")), na.rm = TRUE),
    IM_al= rowSums(select(., starts_with("IM")), na.rm = TRUE),
    MorIden_al= rowSums(select(., starts_with("MorIden")), na.rm = TRUE),
    moralSeImag_al= rowSums(select(., starts_with("moralSeImag")), na.rm = TRUE),
    IPC_al = (rowSums(select(., starts_with("IPC")), na.rm = TRUE)+24)
  )%>%mutate(gad = case_when(
    gad_al >= 0 & gad_al <= 4 ~ "无",
    gad_al >= 5 & gad_al <= 9 ~ "轻度",
    gad_al >= 10 & gad_al <= 14 ~ "中度",
    gad_al >= 15 ~ "重度",
    TRUE ~ NA_character_
  ))%>%
   mutate(phq = case_when(
    phq_al >= 0 & phq_al <= 4 ~ "无",
    phq_al >= 5 & phq_al <= 9 ~ "轻度",
    phq_al >= 10 & phq_al <= 14 ~ "中度",
    phq_al >= 15 & phq_al <= 19 ~ "中重度",
     phq_al >= 20  ~ "重度",
    TRUE ~ NA_character_
  ))
  

```

```{r}
day3_q <-read.csv("../../Data/all//day3_q_all.csv")#修改phase_002
day3_q_1  <- day3_q  %>%
    rename(ability_rating = domain_rating_1, 
           physical_attraction = domain_rating_2,
           material_wealth = domain_rating_3,
           social_ability = domain_rating_4,
           moral_rating=domain_rating_5,
           )%>%
  mutate(
    phq_al = rowSums(select(., starts_with("phq")), na.rm = TRUE),
    gad_al = rowSums(select(., starts_with("gad")), na.rm = TRUE),
    selfclarity_al = rowSums(select(., starts_with("selfclarity")), na.rm = TRUE),
    ses_al = rowSums(select(., starts_with("ses")), na.rm = TRUE),
    coreself_al =rowSums(select(., starts_with("coreself")), na.rm = TRUE),
    SGPS_al = rowSums(select(., starts_with("SGPS")), na.rm = TRUE),
    hsns_al = rowSums(select(., starts_with("hsns")), na.rm = TRUE),
    NPI_al = rowSums(select(., starts_with("NPI")), na.rm = TRUE),
    swb_al = rowSums(select(., starts_with("swb")), na.rm = TRUE),
    LOT_al = rowSums(select(., starts_with("LOT")), na.rm = TRUE),
    sde_al= rowSums(select(., starts_with("sde")), na.rm = TRUE),
    IM_al= rowSums(select(., starts_with("IM")), na.rm = TRUE),
    MorIden_al= rowSums(select(., starts_with("MorIden")), na.rm = TRUE),
    moralSeImag_al= rowSums(select(., starts_with("moralSeImag")), na.rm = TRUE),
    IPC_al = (rowSums(select(., starts_with("IPC")), na.rm = TRUE)+24)
  )

```

## 利用day3的数据计算各问卷信度分析（内部一致性系数alpha）
```{r 内部一致性系数作为信度}
jmv_reliability <- function(data, column_prefix) {
  selected_columns <- select(data, starts_with(column_prefix), -paste0(column_prefix, "_al"))%>%
  jmv::reliability(
    vars = colnames(.),
    alphaScale = TRUE,
    omegaScale = TRUE,
    meanScale = TRUE,sdScale=TRUE,# provide the mean and sd
    corPlot = TRUE,
    alphaItems=TRUE,omegaItems=TRUE,# provide what the Cronbach's alpha/McDonald's omega would be if the item was dropped
    meanItems=TRUE,sdItems=TRUE, # provide item means and sd
    itemRestCor = TRUE # provide item-rest correlations
  )%>%
  print()
}
```

```{r domain_selfesteem}
day3_q_1 %>%
  select(ability_rating,physical_attraction,material_wealth, social_ability,moral_rating) %>%
  jmv::reliability( vars = colnames(.),
    alphaScale = TRUE,
    omegaScale = TRUE,
    meanScale = TRUE,sdScale=TRUE,# provide the mean and sd
    corPlot = TRUE,
    alphaItems=TRUE,omegaItems=TRUE,# provide what the Cronbach's alpha/McDonald's omega would be if the item was dropped
    meanItems=TRUE,sdItems=TRUE, # provide item means and sd
    itemRestCor = TRUE # provide item-rest correlations
  )%>%
  print()
```


```{r sde 内部一致性}

 jmv_reliability(day3_q_1, "sde")
```
```{r IM}
jmv_reliability(day3_q_1, "IM")
```
```{r}
jmv_reliability(day3_q_1, "MorIden")
```
```{r}
jmv_reliability(day3_q_1, "phq")
```
```{r}
jmv_reliability(day3_q_1, "gad")
```
```{r}
jmv_reliability(day3_q_1, "hsns")
```
```{r}
jmv_reliability(day3_q_1, "ses")
```
```{r}
jmv_reliability(day3_q_1, "swb")
```
```{r}
jmv_reliability(day3_q_1, "LOT")
```
```{r}
jmv_reliability(day3_q_1, "NPI")
```
```{r}
jmv_reliability(day3_q_1, "SGPS")
```
```{r}
jmv_reliability(day3_q_1, "IPC")
```
```{r}
jmv_reliability(day3_q_1, "moralSeImag")
```
```{r}
jmv_reliability(day3_q_1, "coreself")
```
```{r}
jmv_reliability(day3_q_1, "selfclarity")
```


## 利用day0t2和day3的数据计算各问卷的重测信度分析（总分的spearman correlation）
```{r 计算前后测的斯皮尔曼相关，重测信度}

#选择要算重测信度的量表
questionnaires <- c("IPC_al", "LOT_al", "swb_al", "NPI_al", "hsns_al", "SGPS_al", "coreself_al", "ses_al", "selfclarity_al", "gad_al", "phq_al","MorIden_al","moralSeImag_al","sde_al","IM_al")

# 计算重测信度

# 存储计算的重测信度
reliabilities <- data.frame(questionnaire = character(0), reliability = numeric(0))

for (questionnaire in questionnaires) {
  # 选择两次测量的数据，for循环
  data1 <- day0t2_q [, c("ID", questionnaire)]
  data2 <- day3_q_1 [, c("ID", questionnaire)]
  
  # 合并数据框
  combined_data <- merge(data1, data2, by = "ID", suffixes = c("_1", "_2"))
  
  # 计算重测信度，利用pearson积差相关
  reliability <- cor(combined_data[, paste(questionnaire, "_1", sep = "")], combined_data[, paste(questionnaire, "_2", sep = "")],method = "pearson", use = "pairwise")
  
  # 存储结果
  reliabilities <- rbind(reliabilities, data.frame(questionnaire = questionnaire, reliability = reliability))
}

# 输出重测信度
print(reliabilities)

```


#
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
```{r}
#探索性因素分析
library(psych)
#KMO鉴定，小于零点五无法接受
?psych::cortest.bartlett
KMO(data)
#进行Bartlett球形检验，p<0.01 
cortest.bartlett(data)
#利用fa()函数分析量表效度
fa(data,fm="pa",nfactor=4,rotate="varimax")#fm因素萃取法--vaiirmax最大变异法，nfacto提取因子数，rotate转轴方法
print(fit,cut=0.35,sort=True)
#绘图
fit1<-fa(data,fm="pa",nfactor=4,rotate="varimax")
fa.diagram(fit1,cut=0.35,sort=TRUE,digits=2)                                                                   
```




# 利用day3做EFA
```{r bruceR对day3的各分量表总分以及领域自尊5维度的相关热图}
day3_q_1%>%
  select(.,ends_with("_al"),ability_rating,physical_attraction,material_wealth, social_ability,moral_rating)%>%
bruceR::Corr(.,
  method = "spearman",#"pearson" (default), "spearman", or "kendall".
  p.adjust = "none",#"none", "fdr", "holm", "bonferroni
  all.as.numeric = TRUE,
  digits = 2,
  file = NULL,#File name of MS Word (.doc).
  plot = TRUE,
  plot.r.size = 4,
  plot.colors = NULL,
  plot.file = NULL,
  plot.width =20,
  plot.height =20,
  plot.dpi = 500)
```

# 判断是否适合EFA
```{r}

day3_q_cor<-day3_q_1%>%
  #select(-ends_with("_al"),-ID,-X,-ParticipantID,)%>%
  select(.,ends_with("_al"),ability_rating,physical_attraction,material_wealth, social_ability,moral_rating)

 cortest.bartlett(day3_q_cor)
KMO(day3_q_cor)
```


```{r}
cortest.bartlett(day3_q_cor)
```

# 确定因子数-------- Bayesian Information Criteria (BIC) is a criterion for model selection
```{r}
factor.num = fa.parallel(day3_q_cor,fa='both',n.iter = 100,
  main='我的碎石图')
```
```{r}

day3_q_fa<-day3_q_cor%>%fa(.,fm="pa",nfactor=3,rotate="promax")
#fm因素萃取法--vaiirmax最大变异法，nfacto提取因子数，rotate转轴方法
print(.,cut=0.35)
```
```{r}
day3_q_cor%>%fa(.,fm="pa",nfactor=3,rotate="promax")%>%    #performed using maximum likelihood estimation，Factor scores were estimated using the tenBerge
fa.diagram(fit1,cut=0.35,sort=TRUE,digits=2)
```


# 因子旋转

# 因子得分
```{r}
factor.scores(day3_q_cor,f=day3_q_fa)
```

# 因子命名与解释



# Factor score robustness.
Confidence intervals on factor loadings were calculated using the “iter” option from “fa” function from the psych package in R, with the fraction of samples kept in each sample set to 90%63. This function runs EFA on 1000 bootstrapped samples, and uses the results to calculate the mean and standard deviation of loadings. The robustness of the factor models was also assessed by dropping out each individual measure and rerunning the analysis. Some measures had large effects on the discovered factors, while others were inconsequential.



# I then used the R mirt package to run exploratory multidimensional IRT analyses, using a graded response model with the Metropolis-Hastings Robbins-Monro (MHRM) algorithm so that I could successfully fit the larger models. In the example shown below, I fit models with dimensionalities from 1 to 10. I then characterized each dimension by examining the items that had the highest/lowest scores on each one and giving a summary label (which was sometimes difficult, in which case I just used "unknown"). See run_mirt.R for details on how the model was run.

```{r}
iclust(day3_q_cor)
```
```{r}

```

